{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment6-LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ravindrabharathi/LSTM/blob/master/Text-Gen-LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3ec6-heaJU6",
        "colab_type": "text"
      },
      "source": [
        "# Text Generation using LSTM \n",
        "\n",
        "We will use a RNN-LSTM model to generate text . The data that we will use is Lewis Carroll's Alice in Wonderland from Gutenberg online library\n",
        "\n",
        "\n",
        "### import required modules "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbW8B2ks6i4y",
        "colab_type": "code",
        "outputId": "c43d69eb-86b2-4a07-b129-576fb3dfaf81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Input\n",
        "from keras.layers import Activation\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n",
        "import nltk.data\n",
        "import string\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KT0IpfluapRI",
        "colab_type": "text"
      },
      "source": [
        "### import nltk to process and analyse the text data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sn0TBQ9bJptl",
        "colab_type": "code",
        "outputId": "768cdbea-ec57-400b-fc76-485a36e18252",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "nltk.download('gutenberg')\n",
        "nltk.download('punkt')\n",
        "from nltk.text import Text\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7VUosOEa7U8",
        "colab_type": "text"
      },
      "source": [
        "### download the alice in wonderland text from gutenberg corpus of nltk and  check the sentence lengths "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "va4A81G-Kykw",
        "colab_type": "code",
        "outputId": "d5f95495-d53a-4bbe-ed0e-c67e90aed93d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from nltk.corpus import gutenberg \n",
        "alice = gutenberg.sents('carroll-alice.txt')\n",
        "sents_list = [\" \".join(sent) for sent in alice]\n",
        "mx_ln=0\n",
        "mn_ln=100\n",
        "for sent in sents_list:\n",
        "  if (len(sent)>mx_ln):\n",
        "    mx_ln=len(sent)\n",
        "  if (len(sent)<mn_ln):\n",
        "    mn_ln=len(sent)\n",
        "print('number of sentences =%d'%len(sents_list))\n",
        "print('max sentence length = %d'%mx_ln) \n",
        "print('min sentence length = %d'%mn_ln)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of sentences =1703\n",
            "max sentence length = 944\n",
            "min sentence length = 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghPvagppbO7C",
        "colab_type": "text"
      },
      "source": [
        "### there is a wide variation in sentence lengths . So instead of splitting by sentences , let us split the data by lines and use it to generate text \n",
        "\n",
        "### get the text as a single file \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKYcn9xM10oZ",
        "colab_type": "code",
        "outputId": "eda098d6-6f1c-46e6-8144-0a9adf50b8ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "!wget 'https://raw.githubusercontent.com/srbharathee/DL/master/lewis_carrol.txt'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-07-26 05:27:22--  https://raw.githubusercontent.com/srbharathee/DL/master/lewis_carrol.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 144431 (141K) [text/plain]\n",
            "Saving to: ‘lewis_carrol.txt’\n",
            "\n",
            "\rlewis_carrol.txt      0%[                    ]       0  --.-KB/s               \rlewis_carrol.txt    100%[===================>] 141.05K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2019-07-26 05:27:22 (3.75 MB/s) - ‘lewis_carrol.txt’ saved [144431/144431]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VS9DxNSqbr2N",
        "colab_type": "text"
      },
      "source": [
        "### print out the head portion to check downloaded file is in order "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGrBlGpu3Met",
        "colab_type": "code",
        "outputId": "5085730f-27e1-4b3d-d3c4-7e96c42f2763",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "!head -20 'lewis_carrol.txt'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ALICE'S ADVENTURES IN WONDERLAND\n",
            "\n",
            "Lewis Carroll\n",
            "\n",
            "THE MILLENNIUM FULCRUM EDITION 3.0\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "CHAPTER I. Down the Rabbit-Hole\n",
            "\n",
            "Alice was beginning to get very tired of sitting by her sister on the\n",
            "bank, and of having nothing to do: once or twice she had peeped into the\n",
            "book her sister was reading, but it had no pictures or conversations in\n",
            "it, 'and what is the use of a book,' thought Alice 'without pictures or\n",
            "conversations?'\n",
            "\n",
            "So she was considering in her own mind (as well as she could, for the\n",
            "hot day made her feel very sleepy and stupid), whether the pleasure\n",
            "of making a daisy-chain would be worth the trouble of getting up and\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ce6ljW6Eb1W8",
        "colab_type": "text"
      },
      "source": [
        "### read lines from the file "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qn72QOsIPBw9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('lewis_carrol.txt', 'r') as f:\n",
        "  lines=f.readlines()\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qYO-bXIb538",
        "colab_type": "text"
      },
      "source": [
        "### print some stats for the set of lines "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kYw0BMrROnS",
        "colab_type": "code",
        "outputId": "3056f477-7b4d-49f6-d47f-f9ee4efbe3db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(\"number of lines = %d\"%(len(lines)))  \n",
        "clean_up=[]\n",
        "max_l=0\n",
        "for line in lines:\n",
        "  \n",
        "  if (len(line)<5):\n",
        "    clean_up.append(line)\n",
        "  if (len(line)>max_l):\n",
        "    max_l=len(line)\n",
        "  if (len(line)>500):\n",
        "    print(\"large  \"+str(len(line)))\n",
        "print(\"number of lines with length <5 = %d\"%len(clean_up))    \n",
        "print(\"max length = %d \"%max_l)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of lines = 3339\n",
            "number of lines with length <5 = 858\n",
            "max length = 75 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfrl9FP4cV6Z",
        "colab_type": "text"
      },
      "source": [
        "### clean up the data , remove return and new line chars , remove punctuation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nmsiIOMRieo",
        "colab_type": "code",
        "outputId": "73644bd8-3c81-4225-e911-d922216ece6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "large_lines=[]\n",
        "medium_lines=[]\n",
        "small_lines=[]\n",
        "max_l=0\n",
        "cleaned_lines=[]\n",
        "\n",
        "for line in lines:\n",
        "  #strip return and new line characters \n",
        "  line=line.strip('\\r\\n')\n",
        "  \n",
        "  \n",
        "  if (len(line)>10 ):\n",
        "    #remove punctuations \n",
        "    line=line.translate(str.maketrans('', '', string.punctuation))\n",
        "    #convert all chars to lowercase \n",
        "    line=line.lower()\n",
        "    cleaned_lines.append(line)\n",
        "    if (len(line)<40):\n",
        "      #print(line)\n",
        "      small_lines.append(line)\n",
        "    elif (len(line)<60):\n",
        "      medium_lines.append(line)\n",
        "    else:\n",
        "      large_lines.append(line)\n",
        "  if (len(line)>max_l):\n",
        "    max_l=len(line)   \n",
        "print(' cleaned lines = %d \\n small lines(len <40)  =%d \\n medium lines(len <60) = %d \\n large lines(len >=60) = %d \\n max line length =%d\\n\\n' %(len(cleaned_lines), len(small_lines),len(medium_lines),len(large_lines), max_l))  \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "line_size=[len(small_lines),len(medium_lines),len(large_lines)]\n",
        "line_cat=['small lines\\n(len <40)','medium lines\\n(len <60)','large lines\\n(len >=60)']\n",
        "y_pos = np.arange(len(line_cat))\n",
        "plt.bar(y_pos, line_size)\n",
        "plt.xticks(y_pos, line_cat)\n",
        "\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " cleaned lines = 2412 \n",
            " small lines(len <40)  =537 \n",
            " medium lines(len <60) = 328 \n",
            " large lines(len >=60) = 1547 \n",
            " max line length =73\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEHCAYAAACncpHfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAy16uUacE8K",
        "colab_type": "text"
      },
      "source": [
        "### here we see that the variation is lengths is lesser compared to splitting by sentences "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59bLdMzscOlG",
        "colab_type": "text"
      },
      "source": [
        "### create our raw data and character dictionary of char to integer mapping . This will be our vocabulary "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uw9RfKaY7CXV",
        "colab_type": "code",
        "outputId": "55de7447-d68b-4179-ac4f-e0d06b5ce8de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "raw_text=[]\n",
        "for line in cleaned_lines:\n",
        "  for char1 in line:\n",
        "    raw_text.append(char1)\n",
        "print(len(raw_text))\n",
        "# create mapping of unique chars to integers\n",
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print(\"Total Characters: \", n_chars)\n",
        "print(\"Total Vocab: \", n_vocab)\n",
        "print(chars)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "132379\n",
            "Total Characters:  132379\n",
            "Total Vocab:  29\n",
            "[' ', '0', '3', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kEZIaBWc1R3",
        "colab_type": "text"
      },
      "source": [
        "### use a max length of 73 and pad the lines that are of smaller size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZ-IOJLD5iqe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pad the sentences based on the max length of lines that we found earlier\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "dataX1=[]\n",
        "for line in cleaned_lines:\n",
        "  line=[char_to_int[char] for char in line]\n",
        "  dataX1.append(line)\n",
        "dataX1=pad_sequences(dataX1,maxlen=max_l,padding='pre')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFpqQWv8dAWN",
        "colab_type": "text"
      },
      "source": [
        "### form the dataset to be used for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mXvTcMKpYAu",
        "colab_type": "code",
        "outputId": "2b28ba67-7f10-4801-baa6-baf831de8953",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataX=[]\n",
        "dataY=[]\n",
        "seq_length = max_l\n",
        "\n",
        "'''\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "\tseq_in = raw_text[i:i + seq_length]\n",
        "\tseq_out = raw_text[i + seq_length]\n",
        "\tdataX.append([char_to_int[char] for char in seq_in])\n",
        "\tdataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n",
        "print( \"Total Patterns: \", n_patterns)\n",
        "'''\n",
        "\n",
        "raw_text=[]\n",
        "for line in dataX1:\n",
        "  raw_text.extend(line)\n",
        "for i in range(0,len(raw_text)-seq_length):\n",
        "  seq_in = raw_text[i:i + seq_length]\n",
        "  seq_out = raw_text[i + seq_length]\n",
        "  dataX.append([char for char in seq_in])\n",
        "  dataY.append(seq_out)\n",
        "n_patterns = len(dataX)\n",
        "print(\"Total Patterns: \", n_patterns)  \n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Patterns:  176003\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "calfImZ-dFM2",
        "colab_type": "text"
      },
      "source": [
        "### the reshape training data / predictors and turn the ground truth labels to categorical one hot vectors "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5gJNnHW7RUK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reshape X to be [samples, time steps, features]\n",
        "X = numpy.reshape(dataX, (n_patterns, max_l,1))\n",
        "# normalize\n",
        "X = X / float(n_vocab)\n",
        "# one hot encode the output variable\n",
        "y = np_utils.to_categorical(dataY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ACX_f-zs9Yj",
        "colab_type": "code",
        "outputId": "06cae35f-e746-4dc4-caef-4d8aaef07e2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(X.shape,y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(176003, 73, 1) (176003, 29)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_8jY1OodeDy",
        "colab_type": "text"
      },
      "source": [
        "### build our model . Use Keras functional API . Our model has a dropout of 0.1 for input , has two LSTM layers of size 256 , followed by a dense layer and softmax activation \n",
        "\n",
        "### compile the model using adam optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKzbZ13A7Vmu",
        "colab_type": "code",
        "outputId": "04f44223-8bce-415d-bd5f-f0a2f7fbfb3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "# define the LSTM model , using functional API \n",
        "from keras.models import Model\n",
        "from keras.layers import Embedding,Flatten\n",
        "'''\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(256))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "'''\n",
        "\n",
        "input_layer=Input(shape=(X.shape[1],X.shape[2] ))\n",
        "x= Dropout(0.1)(input_layer)\n",
        "#x=Embedding(n_vocab+1, 64, input_length=max_l,mask_zero=True)(x)\n",
        "\n",
        "x= LSTM(256,return_sequences=True)(x)\n",
        "x= Dropout(0.1)(x)\n",
        "x=LSTM(256,return_sequences=True)(x)\n",
        "x=Dropout(0.1)(x)\n",
        "#x=LSTM(256,return_sequences=True)(x)\n",
        "#x=Dropout(0.1)(x)\n",
        "x=LSTM(256,return_sequences=False)(x)\n",
        "x=Dense(y.shape[1])(x)\n",
        "\n",
        "output=Activation('softmax')(x)\n",
        "\n",
        "model=Model(input_layer,output)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0726 05:27:31.380825 140592439719808 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0726 05:27:31.422128 140592439719808 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0726 05:27:31.431694 140592439719808 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0726 05:27:31.445803 140592439719808 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0726 05:27:31.473825 140592439719808 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0726 05:27:32.584960 140592439719808 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0726 05:27:32.618633 140592439719808 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlPXCwrvd8BL",
        "colab_type": "text"
      },
      "source": [
        "### print model summary "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S93uXVva5vVw",
        "colab_type": "code",
        "outputId": "cacdf9f8-42e2-4d85-b145-8c583e840102",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 73, 1)             0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 73, 1)             0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 73, 256)           264192    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 73, 256)           0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 73, 256)           525312    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 73, 256)           0         \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 256)               525312    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 29)                7453      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 29)                0         \n",
            "=================================================================\n",
            "Total params: 1,322,269\n",
            "Trainable params: 1,322,269\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1p3qjZAQeCyo",
        "colab_type": "text"
      },
      "source": [
        "### print X and y shape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKrQWEO-d3E8",
        "colab_type": "code",
        "outputId": "989e0fd7-f93b-4e34-e0db-2abd863cd74b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(X.shape,y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(176003, 73, 1) (176003, 29)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bDlfhfreGtI",
        "colab_type": "text"
      },
      "source": [
        "### mount Google drive in order to save the trained model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvgvHBSRxIQI",
        "colab_type": "code",
        "outputId": "a0874249-3006-49cd-b7dc-0497336378da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTrgNNUWeNOS",
        "colab_type": "text"
      },
      "source": [
        "### define a ModelCheckpoint callback to save the model during training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3Yiymf97Zp0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the checkpoint\n",
        "filepath=\"/gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPZobSCOeS4B",
        "colab_type": "text"
      },
      "source": [
        "### we will train the model for 100 epochs . Since LSTM /RNN takes a long time to train we will split the training into 5 sets of 20 epochs . We will use a batch size of 128 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JTJmsfc7fsd",
        "colab_type": "code",
        "outputId": "83a663e9-ea41-4da1-dd33-1de3ceb19408",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0725 05:04:59.135103 140331015251840 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "176003/176003 [==============================] - 601s 3ms/step - loss: 2.1412\n",
            "\n",
            "Epoch 00001: loss improved from inf to 2.14124, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 2/20\n",
            "176003/176003 [==============================] - 593s 3ms/step - loss: 1.8466\n",
            "\n",
            "Epoch 00002: loss improved from 2.14124 to 1.84664, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 3/20\n",
            "176003/176003 [==============================] - 593s 3ms/step - loss: 1.7089\n",
            "\n",
            "Epoch 00003: loss improved from 1.84664 to 1.70893, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 4/20\n",
            "176003/176003 [==============================] - 598s 3ms/step - loss: 1.6206\n",
            "\n",
            "Epoch 00004: loss improved from 1.70893 to 1.62064, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 5/20\n",
            "176003/176003 [==============================] - 593s 3ms/step - loss: 1.5647\n",
            "\n",
            "Epoch 00005: loss improved from 1.62064 to 1.56468, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 6/20\n",
            "176003/176003 [==============================] - 597s 3ms/step - loss: 1.5143\n",
            "\n",
            "Epoch 00006: loss improved from 1.56468 to 1.51425, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 7/20\n",
            "176003/176003 [==============================] - 588s 3ms/step - loss: 1.4719\n",
            "\n",
            "Epoch 00007: loss improved from 1.51425 to 1.47188, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 8/20\n",
            "176003/176003 [==============================] - 585s 3ms/step - loss: 1.4356\n",
            "\n",
            "Epoch 00008: loss improved from 1.47188 to 1.43557, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 9/20\n",
            "176003/176003 [==============================] - 588s 3ms/step - loss: 1.4091\n",
            "\n",
            "Epoch 00009: loss improved from 1.43557 to 1.40907, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 10/20\n",
            "176003/176003 [==============================] - 587s 3ms/step - loss: 1.3779\n",
            "\n",
            "Epoch 00010: loss improved from 1.40907 to 1.37792, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 11/20\n",
            "176003/176003 [==============================] - 596s 3ms/step - loss: 1.3547\n",
            "\n",
            "Epoch 00011: loss improved from 1.37792 to 1.35473, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 12/20\n",
            "176003/176003 [==============================] - 592s 3ms/step - loss: 1.3355\n",
            "\n",
            "Epoch 00012: loss improved from 1.35473 to 1.33546, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 13/20\n",
            "176003/176003 [==============================] - 596s 3ms/step - loss: 1.3119\n",
            "\n",
            "Epoch 00013: loss improved from 1.33546 to 1.31191, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 14/20\n",
            "176003/176003 [==============================] - 597s 3ms/step - loss: 1.2990\n",
            "\n",
            "Epoch 00014: loss improved from 1.31191 to 1.29901, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 15/20\n",
            "176003/176003 [==============================] - 599s 3ms/step - loss: 1.2769\n",
            "\n",
            "Epoch 00015: loss improved from 1.29901 to 1.27695, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 16/20\n",
            "176003/176003 [==============================] - 597s 3ms/step - loss: 1.2667\n",
            "\n",
            "Epoch 00016: loss improved from 1.27695 to 1.26669, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 17/20\n",
            "176003/176003 [==============================] - 590s 3ms/step - loss: 1.2503\n",
            "\n",
            "Epoch 00017: loss improved from 1.26669 to 1.25031, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 18/20\n",
            "176003/176003 [==============================] - 593s 3ms/step - loss: 1.2424\n",
            "\n",
            "Epoch 00018: loss improved from 1.25031 to 1.24243, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 19/20\n",
            "176003/176003 [==============================] - 592s 3ms/step - loss: 1.2271\n",
            "\n",
            "Epoch 00019: loss improved from 1.24243 to 1.22710, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 20/20\n",
            "176003/176003 [==============================] - 590s 3ms/step - loss: 1.2172\n",
            "\n",
            "Epoch 00020: loss improved from 1.22710 to 1.21723, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa103cbb320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ve8u4Wb3emJf",
        "colab_type": "text"
      },
      "source": [
        "### epoch 21-40 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNT-0s26QXcg",
        "colab_type": "code",
        "outputId": "bf651c10-4292-415d-ff6c-a9c3e16dfe7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "176003/176003 [==============================] - 594s 3ms/step - loss: 1.2074\n",
            "\n",
            "Epoch 00001: loss improved from 1.21723 to 1.20743, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 2/20\n",
            "176003/176003 [==============================] - 592s 3ms/step - loss: 1.1951\n",
            "\n",
            "Epoch 00002: loss improved from 1.20743 to 1.19514, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 3/20\n",
            "176003/176003 [==============================] - 589s 3ms/step - loss: 1.1865\n",
            "\n",
            "Epoch 00003: loss improved from 1.19514 to 1.18647, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 4/20\n",
            "176003/176003 [==============================] - 598s 3ms/step - loss: 1.1765\n",
            "\n",
            "Epoch 00004: loss improved from 1.18647 to 1.17648, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 5/20\n",
            "176003/176003 [==============================] - 594s 3ms/step - loss: 1.1662\n",
            "\n",
            "Epoch 00005: loss improved from 1.17648 to 1.16622, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 6/20\n",
            "176003/176003 [==============================] - 589s 3ms/step - loss: 1.1575\n",
            "\n",
            "Epoch 00006: loss improved from 1.16622 to 1.15753, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 7/20\n",
            "176003/176003 [==============================] - 594s 3ms/step - loss: 1.1498\n",
            "\n",
            "Epoch 00007: loss improved from 1.15753 to 1.14984, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 8/20\n",
            "176003/176003 [==============================] - 589s 3ms/step - loss: 1.1429\n",
            "\n",
            "Epoch 00008: loss improved from 1.14984 to 1.14291, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 9/20\n",
            "176003/176003 [==============================] - 592s 3ms/step - loss: 1.1353\n",
            "\n",
            "Epoch 00009: loss improved from 1.14291 to 1.13532, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 10/20\n",
            "176003/176003 [==============================] - 593s 3ms/step - loss: 1.1274\n",
            "\n",
            "Epoch 00010: loss improved from 1.13532 to 1.12744, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 11/20\n",
            "176003/176003 [==============================] - 590s 3ms/step - loss: 1.1211\n",
            "\n",
            "Epoch 00011: loss improved from 1.12744 to 1.12115, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 12/20\n",
            "176003/176003 [==============================] - 589s 3ms/step - loss: 1.1175\n",
            "\n",
            "Epoch 00012: loss improved from 1.12115 to 1.11747, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 13/20\n",
            "176003/176003 [==============================] - 592s 3ms/step - loss: 1.1075\n",
            "\n",
            "Epoch 00013: loss improved from 1.11747 to 1.10746, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 14/20\n",
            "176003/176003 [==============================] - 592s 3ms/step - loss: 1.1067\n",
            "\n",
            "Epoch 00014: loss improved from 1.10746 to 1.10666, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 15/20\n",
            "176003/176003 [==============================] - 589s 3ms/step - loss: 1.0945\n",
            "\n",
            "Epoch 00015: loss improved from 1.10666 to 1.09455, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 16/20\n",
            "176003/176003 [==============================] - 592s 3ms/step - loss: 1.0912\n",
            "\n",
            "Epoch 00016: loss improved from 1.09455 to 1.09116, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 17/20\n",
            "176003/176003 [==============================] - 593s 3ms/step - loss: 1.0897\n",
            "\n",
            "Epoch 00017: loss improved from 1.09116 to 1.08974, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 18/20\n",
            "176003/176003 [==============================] - 594s 3ms/step - loss: 1.0761\n",
            "\n",
            "Epoch 00018: loss improved from 1.08974 to 1.07613, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 19/20\n",
            "176003/176003 [==============================] - 597s 3ms/step - loss: 1.0762\n",
            "\n",
            "Epoch 00019: loss did not improve from 1.07613\n",
            "Epoch 20/20\n",
            "176003/176003 [==============================] - 594s 3ms/step - loss: 1.0730\n",
            "\n",
            "Epoch 00020: loss improved from 1.07613 to 1.07302, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa0fde447f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFJJJZR5erR5",
        "colab_type": "text"
      },
      "source": [
        "### epoch 41-60 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQlq52USvKea",
        "colab_type": "code",
        "outputId": "16237386-1b2a-46db-bfa9-ced3b96fb0ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "176003/176003 [==============================] - 591s 3ms/step - loss: 1.0672\n",
            "\n",
            "Epoch 00001: loss improved from 1.07302 to 1.06717, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 2/20\n",
            "176003/176003 [==============================] - 595s 3ms/step - loss: 1.0667\n",
            "\n",
            "Epoch 00002: loss improved from 1.06717 to 1.06672, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 3/20\n",
            "176003/176003 [==============================] - 592s 3ms/step - loss: 1.0591\n",
            "\n",
            "Epoch 00003: loss improved from 1.06672 to 1.05912, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 4/20\n",
            "176003/176003 [==============================] - 592s 3ms/step - loss: 1.0540\n",
            "\n",
            "Epoch 00004: loss improved from 1.05912 to 1.05397, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 5/20\n",
            "176003/176003 [==============================] - 596s 3ms/step - loss: 1.0443\n",
            "\n",
            "Epoch 00005: loss improved from 1.05397 to 1.04428, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 6/20\n",
            "176003/176003 [==============================] - 593s 3ms/step - loss: 1.0459\n",
            "\n",
            "Epoch 00006: loss did not improve from 1.04428\n",
            "Epoch 7/20\n",
            "176003/176003 [==============================] - 592s 3ms/step - loss: 1.0388\n",
            "\n",
            "Epoch 00007: loss improved from 1.04428 to 1.03876, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 8/20\n",
            "176003/176003 [==============================] - 596s 3ms/step - loss: 1.0310\n",
            "\n",
            "Epoch 00008: loss improved from 1.03876 to 1.03104, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 9/20\n",
            "176003/176003 [==============================] - 596s 3ms/step - loss: 1.0344\n",
            "\n",
            "Epoch 00009: loss did not improve from 1.03104\n",
            "Epoch 10/20\n",
            "176003/176003 [==============================] - 597s 3ms/step - loss: 1.0270\n",
            "\n",
            "Epoch 00010: loss improved from 1.03104 to 1.02701, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 11/20\n",
            "176003/176003 [==============================] - 605s 3ms/step - loss: 1.0224\n",
            "\n",
            "Epoch 00011: loss improved from 1.02701 to 1.02240, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 12/20\n",
            "176003/176003 [==============================] - 603s 3ms/step - loss: 1.0173\n",
            "\n",
            "Epoch 00012: loss improved from 1.02240 to 1.01734, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 13/20\n",
            "176003/176003 [==============================] - 600s 3ms/step - loss: 1.0148\n",
            "\n",
            "Epoch 00013: loss improved from 1.01734 to 1.01480, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 14/20\n",
            "176003/176003 [==============================] - 601s 3ms/step - loss: 1.0160\n",
            "\n",
            "Epoch 00014: loss did not improve from 1.01480\n",
            "Epoch 15/20\n",
            "176003/176003 [==============================] - 599s 3ms/step - loss: 1.0126\n",
            "\n",
            "Epoch 00015: loss improved from 1.01480 to 1.01260, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 16/20\n",
            "176003/176003 [==============================] - 598s 3ms/step - loss: 1.0102\n",
            "\n",
            "Epoch 00016: loss improved from 1.01260 to 1.01019, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 17/20\n",
            "176003/176003 [==============================] - 599s 3ms/step - loss: 1.0042\n",
            "\n",
            "Epoch 00017: loss improved from 1.01019 to 1.00424, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 18/20\n",
            "176003/176003 [==============================] - 596s 3ms/step - loss: 1.0028\n",
            "\n",
            "Epoch 00018: loss improved from 1.00424 to 1.00282, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 19/20\n",
            "176003/176003 [==============================] - 597s 3ms/step - loss: 0.9977\n",
            "\n",
            "Epoch 00019: loss improved from 1.00282 to 0.99769, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 20/20\n",
            "176003/176003 [==============================] - 597s 3ms/step - loss: 0.9891\n",
            "\n",
            "Epoch 00020: loss improved from 0.99769 to 0.98911, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa0f125cc50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoDnW_H7etz5",
        "colab_type": "text"
      },
      "source": [
        "### epoch 61-80"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0sCeMxOO4HY",
        "colab_type": "code",
        "outputId": "2021f998-d021-4295-9713-c9fe33b9d718",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        }
      },
      "source": [
        "model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "176003/176003 [==============================] - 595s 3ms/step - loss: 0.9883\n",
            "\n",
            "Epoch 00001: loss improved from 0.98911 to 0.98826, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 2/20\n",
            "176003/176003 [==============================] - 597s 3ms/step - loss: 0.9889\n",
            "\n",
            "Epoch 00002: loss did not improve from 0.98826\n",
            "Epoch 3/20\n",
            "176003/176003 [==============================] - 598s 3ms/step - loss: 0.9889\n",
            "\n",
            "Epoch 00003: loss did not improve from 0.98826\n",
            "Epoch 4/20\n",
            "176003/176003 [==============================] - 613s 3ms/step - loss: 0.9878\n",
            "\n",
            "Epoch 00004: loss improved from 0.98826 to 0.98785, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 5/20\n",
            "176003/176003 [==============================] - 614s 3ms/step - loss: 0.9803\n",
            "\n",
            "Epoch 00005: loss improved from 0.98785 to 0.98035, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 6/20\n",
            "176003/176003 [==============================] - 617s 4ms/step - loss: 0.9830\n",
            "\n",
            "Epoch 00006: loss did not improve from 0.98035\n",
            "Epoch 7/20\n",
            "176003/176003 [==============================] - 616s 4ms/step - loss: 0.9807\n",
            "\n",
            "Epoch 00007: loss did not improve from 0.98035\n",
            "Epoch 8/20\n",
            "176003/176003 [==============================] - 617s 4ms/step - loss: 0.9744\n",
            "\n",
            "Epoch 00008: loss improved from 0.98035 to 0.97443, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 9/20\n",
            "176003/176003 [==============================] - 617s 4ms/step - loss: 0.9687\n",
            "\n",
            "Epoch 00009: loss improved from 0.97443 to 0.96866, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 10/20\n",
            "176003/176003 [==============================] - 616s 3ms/step - loss: 0.9710\n",
            "\n",
            "Epoch 00010: loss did not improve from 0.96866\n",
            "Epoch 11/20\n",
            "176003/176003 [==============================] - 616s 4ms/step - loss: 0.9688\n",
            "\n",
            "Epoch 00011: loss did not improve from 0.96866\n",
            "Epoch 12/20\n",
            "176003/176003 [==============================] - 617s 4ms/step - loss: 0.9617\n",
            "\n",
            "Epoch 00012: loss improved from 0.96866 to 0.96169, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 13/20\n",
            "  4736/176003 [..............................] - ETA: 9:59 - loss: 0.9386"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRyZJjccKoof",
        "colab_type": "text"
      },
      "source": [
        "###session ended at epoch 72 .So we will load the saved model weights , compile and continue training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hnd72gfyLEN9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the network weights\n",
        "\n",
        "model.load_weights(filepath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9okBS_BDLSDb",
        "colab_type": "text"
      },
      "source": [
        "### epoch 73 - 80 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPkwU8N5K8JY",
        "colab_type": "code",
        "outputId": "d09740df-1524-47f0-aa29-3b15aabe1fc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        }
      },
      "source": [
        "#compile the model and train until 100 epochs \n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
        "model.fit(X, y, epochs=8, batch_size=128, callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0725 17:30:22.315096 140532679919488 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/8\n",
            "176003/176003 [==============================] - 597s 3ms/step - loss: 0.9590 - acc: 0.7147\n",
            "\n",
            "Epoch 00001: loss improved from inf to 0.95897, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 2/8\n",
            "176003/176003 [==============================] - 596s 3ms/step - loss: 0.9633 - acc: 0.7122\n",
            "\n",
            "Epoch 00002: loss did not improve from 0.95897\n",
            "Epoch 3/8\n",
            "176003/176003 [==============================] - 595s 3ms/step - loss: 0.9551 - acc: 0.7157\n",
            "\n",
            "Epoch 00003: loss improved from 0.95897 to 0.95511, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 4/8\n",
            "176003/176003 [==============================] - 589s 3ms/step - loss: 0.9535 - acc: 0.7162\n",
            "\n",
            "Epoch 00004: loss improved from 0.95511 to 0.95350, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 5/8\n",
            "176003/176003 [==============================] - 590s 3ms/step - loss: 0.9525 - acc: 0.7158\n",
            "\n",
            "Epoch 00005: loss improved from 0.95350 to 0.95250, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 6/8\n",
            "176003/176003 [==============================] - 590s 3ms/step - loss: 0.9516 - acc: 0.7165\n",
            "\n",
            "Epoch 00006: loss improved from 0.95250 to 0.95156, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 7/8\n",
            "176003/176003 [==============================] - 589s 3ms/step - loss: 0.9491 - acc: 0.7167\n",
            "\n",
            "Epoch 00007: loss improved from 0.95156 to 0.94912, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 8/8\n",
            "176003/176003 [==============================] - 588s 3ms/step - loss: 0.9433 - acc: 0.7174\n",
            "\n",
            "Epoch 00008: loss improved from 0.94912 to 0.94327, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcff38c72b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dru6oeZqexmk",
        "colab_type": "text"
      },
      "source": [
        "### epoch 81-100 (session ended at epoch 86)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vKNG3e5NimO",
        "colab_type": "code",
        "outputId": "1da5af31-80b3-42b2-eb26-b38357882d07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
        "model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "176003/176003 [==============================] - 590s 3ms/step - loss: 0.9424 - acc: 0.7174\n",
            "\n",
            "Epoch 00001: loss improved from 0.94327 to 0.94243, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 2/20\n",
            "176003/176003 [==============================] - 589s 3ms/step - loss: 0.9412 - acc: 0.7195\n",
            "\n",
            "Epoch 00002: loss improved from 0.94243 to 0.94121, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 3/20\n",
            "176003/176003 [==============================] - 590s 3ms/step - loss: 0.9385 - acc: 0.7197\n",
            "\n",
            "Epoch 00003: loss improved from 0.94121 to 0.93849, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 4/20\n",
            "176003/176003 [==============================] - 590s 3ms/step - loss: 0.9410 - acc: 0.7185\n",
            "\n",
            "Epoch 00004: loss did not improve from 0.93849\n",
            "Epoch 5/20\n",
            "176003/176003 [==============================] - 590s 3ms/step - loss: 0.9407 - acc: 0.7196\n",
            "\n",
            "Epoch 00005: loss did not improve from 0.93849\n",
            "Epoch 6/20\n",
            "176003/176003 [==============================] - 590s 3ms/step - loss: 0.9371 - acc: 0.7196\n",
            "\n",
            "Epoch 00006: loss improved from 0.93849 to 0.93706, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 7/20\n",
            " 16768/176003 [=>............................] - ETA: 8:50 - loss: 0.9112 - acc: 0.7270"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vllbprAWvVyS"
      },
      "source": [
        "###session ended at epoch 86 .So we will load the saved model weights , compile and continue training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EXWrwsP4vOpe",
        "colab": {}
      },
      "source": [
        "# load the network weights\n",
        "\n",
        "model.load_weights(filepath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9CzC6ACPvOp9"
      },
      "source": [
        "### epoch 87 - 100 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "84cfdcc7-0f5b-41ce-b807-7eaa4808089a",
        "id": "LTGywipavOp-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#compile the model and train until 100 epochs \n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
        "model.fit(X, y, epochs=14, batch_size=128, callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0726 05:28:38.509942 140592439719808 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/14\n",
            "176003/176003 [==============================] - 597s 3ms/step - loss: 0.9173 - acc: 0.7251\n",
            "\n",
            "Epoch 00001: loss improved from inf to 0.91727, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 2/14\n",
            "176003/176003 [==============================] - 592s 3ms/step - loss: 0.9176 - acc: 0.7255\n",
            "\n",
            "Epoch 00002: loss did not improve from 0.91727\n",
            "Epoch 3/14\n",
            "176003/176003 [==============================] - 591s 3ms/step - loss: 0.9175 - acc: 0.7244\n",
            "\n",
            "Epoch 00003: loss did not improve from 0.91727\n",
            "Epoch 4/14\n",
            "176003/176003 [==============================] - 587s 3ms/step - loss: 0.9166 - acc: 0.7259\n",
            "\n",
            "Epoch 00004: loss improved from 0.91727 to 0.91665, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 5/14\n",
            "176003/176003 [==============================] - 588s 3ms/step - loss: 0.9134 - acc: 0.7264\n",
            "\n",
            "Epoch 00005: loss improved from 0.91665 to 0.91341, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 6/14\n",
            "176003/176003 [==============================] - 587s 3ms/step - loss: 0.9106 - acc: 0.7277\n",
            "\n",
            "Epoch 00006: loss improved from 0.91341 to 0.91057, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 7/14\n",
            "176003/176003 [==============================] - 582s 3ms/step - loss: 0.9118 - acc: 0.7270\n",
            "\n",
            "Epoch 00007: loss did not improve from 0.91057\n",
            "Epoch 8/14\n",
            "176003/176003 [==============================] - 582s 3ms/step - loss: 0.9055 - acc: 0.7289\n",
            "\n",
            "Epoch 00008: loss improved from 0.91057 to 0.90551, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 9/14\n",
            "176003/176003 [==============================] - 581s 3ms/step - loss: 0.9067 - acc: 0.7295\n",
            "\n",
            "Epoch 00009: loss did not improve from 0.90551\n",
            "Epoch 10/14\n",
            "176003/176003 [==============================] - 583s 3ms/step - loss: 0.9071 - acc: 0.7282\n",
            "\n",
            "Epoch 00010: loss did not improve from 0.90551\n",
            "Epoch 11/14\n",
            "176003/176003 [==============================] - 583s 3ms/step - loss: 0.9061 - acc: 0.7282\n",
            "\n",
            "Epoch 00011: loss did not improve from 0.90551\n",
            "Epoch 12/14\n",
            "176003/176003 [==============================] - 583s 3ms/step - loss: 0.9023 - acc: 0.7304\n",
            "\n",
            "Epoch 00012: loss improved from 0.90551 to 0.90226, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n",
            "Epoch 13/14\n",
            "176003/176003 [==============================] - 584s 3ms/step - loss: 0.9060 - acc: 0.7280\n",
            "\n",
            "Epoch 00013: loss did not improve from 0.90226\n",
            "Epoch 14/14\n",
            "176003/176003 [==============================] - 583s 3ms/step - loss: 0.8978 - acc: 0.7307\n",
            "\n",
            "Epoch 00014: loss improved from 0.90226 to 0.89784, saving model to /gdrive/My Drive/EIP3/session6/best_model_weights.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdddd847be0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hhyd3ooCe2Dr",
        "colab_type": "text"
      },
      "source": [
        "### load the best model weights saved earlier to use for  prediction and text generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWlbkZ_68DK2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the network weights\n",
        "\n",
        "model.load_weights(filepath)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fa0p5GfQfM1c",
        "colab_type": "text"
      },
      "source": [
        "### form a mapping of integer to char"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHuoz8K_8Hmg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "int_to_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4LeEiAPfSUA",
        "colab_type": "text"
      },
      "source": [
        "### print the mapping of int ot char "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdb4SA979PR3",
        "colab_type": "code",
        "outputId": "06454c25-f2a3-4a60-d53e-4dbafedefed2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(int_to_char)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: ' ', 1: '0', 2: '3', 3: 'a', 4: 'b', 5: 'c', 6: 'd', 7: 'e', 8: 'f', 9: 'g', 10: 'h', 11: 'i', 12: 'j', 13: 'k', 14: 'l', 15: 'm', 16: 'n', 17: 'o', 18: 'p', 19: 'q', 20: 'r', 21: 's', 22: 't', 23: 'u', 24: 'v', 25: 'w', 26: 'x', 27: 'y', 28: 'z'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUwr8WBnfYJF",
        "colab_type": "text"
      },
      "source": [
        "### get a random line from training data to be used as seed and generate 500 characters "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bh3su3pD8L52",
        "colab_type": "code",
        "outputId": "1be1d536-ea92-486f-a62d-5a98c80a00e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "import sys\n",
        "# pick a random seed\n",
        "start = numpy.random.randint(0, len(dataX)-1)\n",
        "pattern = dataX[start]\n",
        "#print(pattern)\n",
        "print(\"Seed:\")\n",
        "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
        "otpt=[]\n",
        "print(\"\\n------------\\n\\nGenerated characters : \")\n",
        "# generate characters\n",
        "for i in range(500):\n",
        "  #print(len(pattern))\n",
        "  #print(pattern)\n",
        "  x = numpy.reshape(pattern, (1, len(pattern),1))\n",
        "  #print(x.shape,len(pattern))\n",
        "  x = x / float(n_vocab)\n",
        "  prediction = model.predict(x, verbose=0)\n",
        "  #print(prediction)\n",
        "  index = numpy.argmax(prediction)\n",
        "  #print(index)\n",
        "  result = int_to_char[index]\n",
        "  #print(result)\n",
        "  seq_in = [int_to_char[value] for value in pattern]\n",
        "  #print(result)\n",
        "  sys.stdout.write(result)\n",
        "  otpt.append(result)\n",
        "  pattern.append(index)\n",
        "  pattern = pattern[1:len(pattern)]\n",
        "\n",
        "print('\\n\\n-----------')\n",
        "print('generated characters as a list : ')\n",
        "print(otpt)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seed:\n",
            "\"  the reason is that im doubtful about                   the temper of you \"\n",
            "\n",
            "------------\n",
            "\n",
            "Generated characters : \n",
            "s het yole er wie dourorsoosooooy fno                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
            "\n",
            "-----------\n",
            "generated characters as a list : \n",
            "['s', ' ', 'h', 'e', 't', ' ', 'y', 'o', 'l', 'e', ' ', 'e', 'r', ' ', 'w', 'i', 'e', ' ', 'd', 'o', 'u', 'r', 'o', 'r', 's', 'o', 'o', 's', 'o', 'o', 'o', 'o', 'y', ' ', 'f', 'n', 'o', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBkpcmdjfh8F",
        "colab_type": "text"
      },
      "source": [
        "### We trained an LSTM model on Alice in wonderland text to generate characters. As we can see from the generated text , it is not perfect and more training and manipulation of training data is required to get better results  "
      ]
    }
  ]
}